{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhonxayMax/6_DL_-for_Vision_Systems_Mohamed-Elgendy/blob/main/CH4_chapter_4_improve_cifar_90_percent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v5ScYs9jMZYL"
      },
      "outputs": [],
      "source": [
        "# Checked 25/05/2025\n",
        "#import dependencies\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "#from keras.utils import np_utils\n",
        "# Import to_categorical directly from keras.utils\n",
        "from keras.utils import to_categorical\n",
        "# Update the import statement for ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(\"GPU Device Name: \", tf.test.gpu_device_name())"
      ],
      "metadata": {
        "id": "s5KMLXWEyFBT",
        "outputId": "abe4bbe5-fe64-45b2-d7c3-f1b82c914dbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "GPU Device Name:  /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Wx56a5EHMZYM",
        "outputId": "1bca3c33-d65a-44b5-e9bd-566e4da8a30c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
            "training data =  (50000, 32, 32, 3)\n",
            "testing data =  (10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# download and split the data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "print(\"training data = \", x_train.shape)\n",
        "print(\"testing data = \", x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "cf_OjIybyWYR",
        "outputId": "6cd41e2d-bbc4-4f5a-ca64-5584c64bf79b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 25 14:13:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0             30W /   70W |     102MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "id": "xU-aEyD7MZYM",
        "outputId": "c69408b0-2720-4bdb-e725-ff7d3b8e01bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.9619245 , -0.91515917, -0.8995707 ],\n",
              "        [-1.2113398 , -1.1645745 , -1.1801629 ],\n",
              "        [-1.1022207 , -1.1333976 , -1.2113398 ],\n",
              "        ...,\n",
              "        [ 0.58133286,  0.17603296, -0.19809005],\n",
              "        [ 0.48780212,  0.06691375, -0.2916208 ],\n",
              "        [ 0.4254483 ,  0.05132529, -0.27603233]],\n",
              "\n",
              "       [[-1.6322283 , -1.5698744 , -1.5698744 ],\n",
              "        [-1.8816435 , -1.8816435 , -1.8816435 ],\n",
              "        [-1.6010513 , -1.756936  , -1.8816435 ],\n",
              "        ...,\n",
              "        [ 0.03573683, -0.5098592 , -1.0242784 ],\n",
              "        [-0.026617  , -0.5878015 , -1.1022207 ],\n",
              "        [ 0.02014837, -0.52544767, -0.9931014 ]],\n",
              "\n",
              "       [[-1.4919322 , -1.5075206 , -1.554286  ],\n",
              "        [-1.6322283 , -1.7725244 , -1.8816435 ],\n",
              "        [-1.117809  , -1.4607552 , -1.756936  ],\n",
              "        ...,\n",
              "        [-0.04220546, -0.57221305, -1.1022207 ],\n",
              "        [-0.01102854, -0.57221305, -1.1022207 ],\n",
              "        [-0.18250158, -0.7436861 , -1.2269284 ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 1.3607558 ,  0.7683944 , -0.38515157],\n",
              "        [ 1.2516366 ,  0.5033906 , -1.3516359 ],\n",
              "        [ 1.2048712 ,  0.62809825, -1.4763436 ],\n",
              "        ...,\n",
              "        [ 0.6125098 ,  0.19162142, -0.79045147],\n",
              "        [-1.0086899 , -1.3984014 , -1.7725244 ],\n",
              "        [-1.0554553 , -1.3516359 , -1.5698744 ]],\n",
              "\n",
              "       [[ 0.924279  ,  0.28515217, -0.38515157],\n",
              "        [ 0.81515974,  0.03573683, -1.2269284 ],\n",
              "        [ 1.0178097 ,  0.36309445, -1.4139898 ],\n",
              "        ...,\n",
              "        [ 0.9866328 ,  0.4254483 , -0.41632846],\n",
              "        [-0.3695631 , -0.91515917, -1.3516359 ],\n",
              "        [-0.5878015 , -1.0554553 , -1.3516359 ]],\n",
              "\n",
              "       [[ 0.8775136 ,  0.36309445, -0.07338238],\n",
              "        [ 0.7372175 ,  0.12926759, -0.41632846],\n",
              "        [ 0.9086905 ,  0.33191755, -0.52544767],\n",
              "        ...,\n",
              "        [ 1.4854635 ,  0.9866328 ,  0.30074063],\n",
              "        [ 0.4722137 , -0.04220546, -0.57221305],\n",
              "        [ 0.03573683, -0.44750538, -0.75927454]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Normalize the data to speed up training\n",
        "mean = np.mean(x_train)\n",
        "std = np.std(x_train)\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        "\n",
        "# let's look at the normalized values of a sample image\n",
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BUdWT70BMZYN",
        "outputId": "f8071c61-5899-4e85-ab8f-501d13190e48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# one-hot encode the labels in train and test datasets\n",
        "# we use “to_categorical” function in keras\n",
        "\n",
        "num_classes = 10\n",
        "# Use to_categorical directly after importing it\n",
        "y_train = to_categorical(y_train,num_classes)\n",
        "y_test = to_categorical(y_test,num_classes)\n",
        "\n",
        "# let's display one of the one-hot encoded labels\n",
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fTjVDFvUMZYN",
        "outputId": "81052c3e-464a-4c06-c9b6-bac0be23cd19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m20,490\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,490</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m309,290\u001b[0m (1.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">309,290</span> (1.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m308,394\u001b[0m (1.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">308,394</span> (1.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# build the model\n",
        "\n",
        "# number of hidden units variable\n",
        "# we are declaring this variable here and use it in our CONV layers to make it easier to update from one place\n",
        "base_hidden_units = 32\n",
        "\n",
        "# l2 regularization hyperparameter\n",
        "weight_decay = 1e-4\n",
        "\n",
        "# instantiate an empty sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# CONV1\n",
        "# notice that we defined the input_shape here because this is the first CONV layer.\n",
        "# we don’t need to do that for the remaining layers\n",
        "model.add(Conv2D(base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV2\n",
        "model.add(Conv2D(base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# CONV3\n",
        "model.add(Conv2D(2*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV4\n",
        "model.add(Conv2D(2*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# CONV5\n",
        "model.add(Conv2D(4*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV6\n",
        "model.add(Conv2D(4*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# FC7\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# print model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4yAcChREMZYO"
      },
      "outputs": [],
      "source": [
        "# data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        "    )\n",
        "\n",
        "# compute the data augmentation on the training set\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": false,
        "id": "CPvt9kbwMZYO",
        "outputId": "ff453afc-edae-4508-cae4-bc814f86fd7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 1.37604, saving model to model.125epochs.keras\n",
            "781/781 - 49s - 63ms/step - accuracy: 0.3720 - loss: 2.1357 - val_accuracy: 0.5312 - val_loss: 1.3760\n",
            "Epoch 2/125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_loss improved from 1.37604 to 1.32420, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.4375 - loss: 1.7495 - val_accuracy: 0.5488 - val_loss: 1.3242\n",
            "Epoch 3/125\n",
            "\n",
            "Epoch 3: val_loss improved from 1.32420 to 1.19752, saving model to model.125epochs.keras\n",
            "781/781 - 64s - 82ms/step - accuracy: 0.5131 - loss: 1.4893 - val_accuracy: 0.6068 - val_loss: 1.1975\n",
            "Epoch 4/125\n",
            "\n",
            "Epoch 4: val_loss improved from 1.19752 to 1.14886, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.5312 - loss: 1.5121 - val_accuracy: 0.6241 - val_loss: 1.1489\n",
            "Epoch 5/125\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.14886\n",
            "781/781 - 40s - 51ms/step - accuracy: 0.5869 - loss: 1.2428 - val_accuracy: 0.6427 - val_loss: 1.1543\n",
            "Epoch 6/125\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.14886\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.5781 - loss: 1.0204 - val_accuracy: 0.6296 - val_loss: 1.1983\n",
            "Epoch 7/125\n",
            "\n",
            "Epoch 7: val_loss improved from 1.14886 to 0.93719, saving model to model.125epochs.keras\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.6330 - loss: 1.1018 - val_accuracy: 0.6930 - val_loss: 0.9372\n",
            "Epoch 8/125\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.93719\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.6562 - loss: 1.0290 - val_accuracy: 0.6948 - val_loss: 0.9416\n",
            "Epoch 9/125\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.93719\n",
            "781/781 - 40s - 51ms/step - accuracy: 0.6626 - loss: 1.0137 - val_accuracy: 0.7026 - val_loss: 0.9476\n",
            "Epoch 10/125\n",
            "\n",
            "Epoch 10: val_loss improved from 0.93719 to 0.88066, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.7188 - loss: 0.8438 - val_accuracy: 0.7182 - val_loss: 0.8807\n",
            "Epoch 11/125\n",
            "\n",
            "Epoch 11: val_loss improved from 0.88066 to 0.85375, saving model to model.125epochs.keras\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.6870 - loss: 0.9467 - val_accuracy: 0.7320 - val_loss: 0.8537\n",
            "Epoch 12/125\n",
            "\n",
            "Epoch 12: val_loss improved from 0.85375 to 0.82206, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.5781 - loss: 1.0415 - val_accuracy: 0.7435 - val_loss: 0.8221\n",
            "Epoch 13/125\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.82206\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.7018 - loss: 0.8955 - val_accuracy: 0.7248 - val_loss: 0.8806\n",
            "Epoch 14/125\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.82206\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.7344 - loss: 0.7312 - val_accuracy: 0.7410 - val_loss: 0.8236\n",
            "Epoch 15/125\n",
            "\n",
            "Epoch 15: val_loss improved from 0.82206 to 0.77273, saving model to model.125epochs.keras\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.7191 - loss: 0.8499 - val_accuracy: 0.7585 - val_loss: 0.7727\n",
            "Epoch 16/125\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.77273\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.6406 - loss: 1.0254 - val_accuracy: 0.7584 - val_loss: 0.7745\n",
            "Epoch 17/125\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.77273\n",
            "781/781 - 39s - 50ms/step - accuracy: 0.7349 - loss: 0.8126 - val_accuracy: 0.7599 - val_loss: 0.7747\n",
            "Epoch 18/125\n",
            "\n",
            "Epoch 18: val_loss improved from 0.77273 to 0.76361, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.7031 - loss: 0.8984 - val_accuracy: 0.7623 - val_loss: 0.7636\n",
            "Epoch 19/125\n",
            "\n",
            "Epoch 19: val_loss improved from 0.76361 to 0.75748, saving model to model.125epochs.keras\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.7447 - loss: 0.7884 - val_accuracy: 0.7694 - val_loss: 0.7575\n",
            "Epoch 20/125\n",
            "\n",
            "Epoch 20: val_loss improved from 0.75748 to 0.75241, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.7500 - loss: 0.7961 - val_accuracy: 0.7673 - val_loss: 0.7524\n",
            "Epoch 21/125\n",
            "\n",
            "Epoch 21: val_loss improved from 0.75241 to 0.74934, saving model to model.125epochs.keras\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.7522 - loss: 0.7608 - val_accuracy: 0.7671 - val_loss: 0.7493\n",
            "Epoch 22/125\n",
            "\n",
            "Epoch 22: val_loss improved from 0.74934 to 0.73301, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8125 - loss: 0.5856 - val_accuracy: 0.7716 - val_loss: 0.7330\n",
            "Epoch 23/125\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.73301\n",
            "781/781 - 40s - 51ms/step - accuracy: 0.7596 - loss: 0.7440 - val_accuracy: 0.7617 - val_loss: 0.7801\n",
            "Epoch 24/125\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.73301\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.7969 - loss: 0.6375 - val_accuracy: 0.7523 - val_loss: 0.8221\n",
            "Epoch 25/125\n",
            "\n",
            "Epoch 25: val_loss improved from 0.73301 to 0.67330, saving model to model.125epochs.keras\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.7677 - loss: 0.7221 - val_accuracy: 0.7940 - val_loss: 0.6733\n",
            "Epoch 26/125\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.67330\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.7656 - loss: 0.7913 - val_accuracy: 0.7831 - val_loss: 0.7208\n",
            "Epoch 27/125\n",
            "\n",
            "Epoch 27: val_loss improved from 0.67330 to 0.65855, saving model to model.125epochs.keras\n",
            "781/781 - 39s - 50ms/step - accuracy: 0.7738 - loss: 0.7100 - val_accuracy: 0.7966 - val_loss: 0.6585\n",
            "Epoch 28/125\n",
            "\n",
            "Epoch 28: val_loss improved from 0.65855 to 0.63931, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.7969 - loss: 0.7032 - val_accuracy: 0.8024 - val_loss: 0.6393\n",
            "Epoch 29/125\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.63931\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.7798 - loss: 0.6911 - val_accuracy: 0.7997 - val_loss: 0.6566\n",
            "Epoch 30/125\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.63931\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.7344 - loss: 0.6400 - val_accuracy: 0.8000 - val_loss: 0.6568\n",
            "Epoch 31/125\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.63931\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.7844 - loss: 0.6792 - val_accuracy: 0.7991 - val_loss: 0.6482\n",
            "Epoch 32/125\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.63931\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8594 - loss: 0.5356 - val_accuracy: 0.7981 - val_loss: 0.6526\n",
            "Epoch 33/125\n",
            "\n",
            "Epoch 33: val_loss improved from 0.63931 to 0.61648, saving model to model.125epochs.keras\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.7878 - loss: 0.6656 - val_accuracy: 0.8112 - val_loss: 0.6165\n",
            "Epoch 34/125\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.61648\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.7344 - loss: 0.7557 - val_accuracy: 0.8091 - val_loss: 0.6251\n",
            "Epoch 35/125\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.61648\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.7937 - loss: 0.6500 - val_accuracy: 0.8150 - val_loss: 0.6262\n",
            "Epoch 36/125\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.61648\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8438 - loss: 0.4311 - val_accuracy: 0.8142 - val_loss: 0.6233\n",
            "Epoch 37/125\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.61648\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.7974 - loss: 0.6410 - val_accuracy: 0.8153 - val_loss: 0.6207\n",
            "Epoch 38/125\n",
            "\n",
            "Epoch 38: val_loss improved from 0.61648 to 0.61073, saving model to model.125epochs.keras\n",
            "781/781 - 3s - 4ms/step - accuracy: 0.7969 - loss: 0.6303 - val_accuracy: 0.8190 - val_loss: 0.6107\n",
            "Epoch 39/125\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.61073\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.7997 - loss: 0.6313 - val_accuracy: 0.8198 - val_loss: 0.6311\n",
            "Epoch 40/125\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.61073\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.7656 - loss: 0.7580 - val_accuracy: 0.8187 - val_loss: 0.6126\n",
            "Epoch 41/125\n",
            "\n",
            "Epoch 41: val_loss improved from 0.61073 to 0.59678, saving model to model.125epochs.keras\n",
            "781/781 - 41s - 52ms/step - accuracy: 0.8001 - loss: 0.6254 - val_accuracy: 0.8229 - val_loss: 0.5968\n",
            "Epoch 42/125\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.59678\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8281 - loss: 0.4995 - val_accuracy: 0.8140 - val_loss: 0.6230\n",
            "Epoch 43/125\n",
            "\n",
            "Epoch 43: val_loss improved from 0.59678 to 0.58296, saving model to model.125epochs.keras\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.8087 - loss: 0.6166 - val_accuracy: 0.8267 - val_loss: 0.5830\n",
            "Epoch 44/125\n",
            "\n",
            "Epoch 44: val_loss improved from 0.58296 to 0.56790, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.7344 - loss: 0.9805 - val_accuracy: 0.8305 - val_loss: 0.5679\n",
            "Epoch 45/125\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.56790\n",
            "781/781 - 40s - 51ms/step - accuracy: 0.8102 - loss: 0.6094 - val_accuracy: 0.8208 - val_loss: 0.6016\n",
            "Epoch 46/125\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.56790\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.7500 - loss: 0.5725 - val_accuracy: 0.8152 - val_loss: 0.6181\n",
            "Epoch 47/125\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.56790\n",
            "781/781 - 40s - 52ms/step - accuracy: 0.8125 - loss: 0.6015 - val_accuracy: 0.8177 - val_loss: 0.6253\n",
            "Epoch 48/125\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.56790\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8125 - loss: 0.5199 - val_accuracy: 0.8174 - val_loss: 0.6298\n",
            "Epoch 49/125\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.56790\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.8178 - loss: 0.5908 - val_accuracy: 0.8188 - val_loss: 0.6118\n",
            "Epoch 50/125\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.56790\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.7812 - loss: 0.7396 - val_accuracy: 0.8291 - val_loss: 0.5729\n",
            "Epoch 51/125\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.56790\n",
            "781/781 - 40s - 52ms/step - accuracy: 0.8163 - loss: 0.5870 - val_accuracy: 0.8268 - val_loss: 0.6012\n",
            "Epoch 52/125\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.56790\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8906 - loss: 0.4649 - val_accuracy: 0.8282 - val_loss: 0.5943\n",
            "Epoch 53/125\n",
            "\n",
            "Epoch 53: val_loss improved from 0.56790 to 0.56481, saving model to model.125epochs.keras\n",
            "781/781 - 39s - 50ms/step - accuracy: 0.8194 - loss: 0.5810 - val_accuracy: 0.8296 - val_loss: 0.5648\n",
            "Epoch 54/125\n",
            "\n",
            "Epoch 54: val_loss improved from 0.56481 to 0.54957, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.6562 - loss: 0.9047 - val_accuracy: 0.8337 - val_loss: 0.5496\n",
            "Epoch 55/125\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.54957\n",
            "781/781 - 40s - 51ms/step - accuracy: 0.8231 - loss: 0.5736 - val_accuracy: 0.8169 - val_loss: 0.6185\n",
            "Epoch 56/125\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.54957\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.7969 - loss: 0.6625 - val_accuracy: 0.8246 - val_loss: 0.5987\n",
            "Epoch 57/125\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.54957\n",
            "781/781 - 40s - 51ms/step - accuracy: 0.8245 - loss: 0.5708 - val_accuracy: 0.8362 - val_loss: 0.5575\n",
            "Epoch 58/125\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.54957\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8594 - loss: 0.5385 - val_accuracy: 0.8320 - val_loss: 0.5636\n",
            "Epoch 59/125\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.54957\n",
            "781/781 - 39s - 50ms/step - accuracy: 0.8263 - loss: 0.5634 - val_accuracy: 0.8416 - val_loss: 0.5566\n",
            "Epoch 60/125\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.54957\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8281 - loss: 0.5786 - val_accuracy: 0.8404 - val_loss: 0.5582\n",
            "Epoch 61/125\n",
            "\n",
            "Epoch 61: val_loss improved from 0.54957 to 0.52901, saving model to model.125epochs.keras\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.8256 - loss: 0.5659 - val_accuracy: 0.8499 - val_loss: 0.5290\n",
            "Epoch 62/125\n",
            "\n",
            "Epoch 62: val_loss improved from 0.52901 to 0.52374, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.7656 - loss: 0.7906 - val_accuracy: 0.8501 - val_loss: 0.5237\n",
            "Epoch 63/125\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.52374\n",
            "781/781 - 39s - 50ms/step - accuracy: 0.8284 - loss: 0.5571 - val_accuracy: 0.8482 - val_loss: 0.5265\n",
            "Epoch 64/125\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.52374\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.7656 - loss: 0.6066 - val_accuracy: 0.8471 - val_loss: 0.5388\n",
            "Epoch 65/125\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.52374\n",
            "781/781 - 42s - 53ms/step - accuracy: 0.8323 - loss: 0.5499 - val_accuracy: 0.8312 - val_loss: 0.5742\n",
            "Epoch 66/125\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.52374\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8281 - loss: 0.5359 - val_accuracy: 0.8299 - val_loss: 0.5828\n",
            "Epoch 67/125\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.52374\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.8351 - loss: 0.5468 - val_accuracy: 0.8413 - val_loss: 0.5488\n",
            "Epoch 68/125\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.52374\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8125 - loss: 0.6588 - val_accuracy: 0.8393 - val_loss: 0.5470\n",
            "Epoch 69/125\n",
            "\n",
            "Epoch 69: val_loss improved from 0.52374 to 0.52046, saving model to model.125epochs.keras\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.8331 - loss: 0.5450 - val_accuracy: 0.8492 - val_loss: 0.5205\n",
            "Epoch 70/125\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.52046\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8594 - loss: 0.4112 - val_accuracy: 0.8492 - val_loss: 0.5274\n",
            "Epoch 71/125\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.52046\n",
            "781/781 - 39s - 50ms/step - accuracy: 0.8402 - loss: 0.5299 - val_accuracy: 0.8416 - val_loss: 0.5409\n",
            "Epoch 72/125\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.52046\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8125 - loss: 0.4259 - val_accuracy: 0.8446 - val_loss: 0.5335\n",
            "Epoch 73/125\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.52046\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.8385 - loss: 0.5330 - val_accuracy: 0.8366 - val_loss: 0.5578\n",
            "Epoch 74/125\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.52046\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.7656 - loss: 0.7028 - val_accuracy: 0.8454 - val_loss: 0.5326\n",
            "Epoch 75/125\n",
            "\n",
            "Epoch 75: val_loss improved from 0.52046 to 0.52029, saving model to model.125epochs.keras\n",
            "781/781 - 29s - 38ms/step - accuracy: 0.8414 - loss: 0.5294 - val_accuracy: 0.8506 - val_loss: 0.5203\n",
            "Epoch 76/125\n",
            "\n",
            "Epoch 76: val_loss improved from 0.52029 to 0.51409, saving model to model.125epochs.keras\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8750 - loss: 0.4702 - val_accuracy: 0.8553 - val_loss: 0.5141\n",
            "Epoch 77/125\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.51409\n",
            "781/781 - 38s - 49ms/step - accuracy: 0.8419 - loss: 0.5241 - val_accuracy: 0.8462 - val_loss: 0.5327\n",
            "Epoch 78/125\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.51409\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8906 - loss: 0.4475 - val_accuracy: 0.8481 - val_loss: 0.5296\n",
            "Epoch 79/125\n",
            "\n",
            "Epoch 79: val_loss improved from 0.51409 to 0.51289, saving model to model.125epochs.keras\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.8439 - loss: 0.5241 - val_accuracy: 0.8548 - val_loss: 0.5129\n",
            "Epoch 80/125\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.51289\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8594 - loss: 0.5133 - val_accuracy: 0.8523 - val_loss: 0.5219\n",
            "Epoch 81/125\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.51289\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.8436 - loss: 0.5184 - val_accuracy: 0.8358 - val_loss: 0.5822\n",
            "Epoch 82/125\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.51289\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8438 - loss: 0.6107 - val_accuracy: 0.8378 - val_loss: 0.5687\n",
            "Epoch 83/125\n",
            "\n",
            "Epoch 83: val_loss improved from 0.51289 to 0.49332, saving model to model.125epochs.keras\n",
            "781/781 - 40s - 51ms/step - accuracy: 0.8454 - loss: 0.5140 - val_accuracy: 0.8612 - val_loss: 0.4933\n",
            "Epoch 84/125\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.49332\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8750 - loss: 0.4831 - val_accuracy: 0.8557 - val_loss: 0.5032\n",
            "Epoch 85/125\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.49332\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.8440 - loss: 0.5187 - val_accuracy: 0.8475 - val_loss: 0.5399\n",
            "Epoch 86/125\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.49332\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8594 - loss: 0.4808 - val_accuracy: 0.8482 - val_loss: 0.5404\n",
            "Epoch 87/125\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.49332\n",
            "781/781 - 39s - 50ms/step - accuracy: 0.8476 - loss: 0.5081 - val_accuracy: 0.8577 - val_loss: 0.5156\n",
            "Epoch 88/125\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.49332\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8594 - loss: 0.3270 - val_accuracy: 0.8560 - val_loss: 0.5183\n",
            "Epoch 89/125\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.49332\n",
            "781/781 - 42s - 54ms/step - accuracy: 0.8486 - loss: 0.5081 - val_accuracy: 0.8490 - val_loss: 0.5283\n",
            "Epoch 90/125\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.49332\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.9062 - loss: 0.3896 - val_accuracy: 0.8513 - val_loss: 0.5198\n",
            "Epoch 91/125\n",
            "\n",
            "Epoch 91: val_loss improved from 0.49332 to 0.47702, saving model to model.125epochs.keras\n",
            "781/781 - 38s - 49ms/step - accuracy: 0.8499 - loss: 0.5045 - val_accuracy: 0.8666 - val_loss: 0.4770\n",
            "Epoch 92/125\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8125 - loss: 0.6223 - val_accuracy: 0.8655 - val_loss: 0.4811\n",
            "Epoch 93/125\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.47702\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.8502 - loss: 0.5018 - val_accuracy: 0.8559 - val_loss: 0.5008\n",
            "Epoch 94/125\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.7969 - loss: 0.6568 - val_accuracy: 0.8581 - val_loss: 0.4961\n",
            "Epoch 95/125\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.47702\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.8506 - loss: 0.5065 - val_accuracy: 0.8467 - val_loss: 0.5395\n",
            "Epoch 96/125\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.7969 - loss: 0.5308 - val_accuracy: 0.8465 - val_loss: 0.5426\n",
            "Epoch 97/125\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.47702\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.8520 - loss: 0.5017 - val_accuracy: 0.8576 - val_loss: 0.4945\n",
            "Epoch 98/125\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8438 - loss: 0.4394 - val_accuracy: 0.8554 - val_loss: 0.5021\n",
            "Epoch 99/125\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.47702\n",
            "781/781 - 41s - 52ms/step - accuracy: 0.8548 - loss: 0.4919 - val_accuracy: 0.8607 - val_loss: 0.5051\n",
            "Epoch 100/125\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8125 - loss: 0.5690 - val_accuracy: 0.8615 - val_loss: 0.5063\n",
            "Epoch 101/125\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.47702\n",
            "781/781 - 38s - 49ms/step - accuracy: 0.8532 - loss: 0.4968 - val_accuracy: 0.8550 - val_loss: 0.5084\n",
            "Epoch 102/125\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.7656 - loss: 0.6655 - val_accuracy: 0.8512 - val_loss: 0.5220\n",
            "Epoch 103/125\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.47702\n",
            "781/781 - 40s - 51ms/step - accuracy: 0.8536 - loss: 0.4904 - val_accuracy: 0.8588 - val_loss: 0.4993\n",
            "Epoch 104/125\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.9062 - loss: 0.4292 - val_accuracy: 0.8568 - val_loss: 0.5039\n",
            "Epoch 105/125\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.47702\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.8552 - loss: 0.4876 - val_accuracy: 0.8539 - val_loss: 0.5240\n",
            "Epoch 106/125\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.7969 - loss: 0.5856 - val_accuracy: 0.8487 - val_loss: 0.5402\n",
            "Epoch 107/125\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.47702\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.8550 - loss: 0.4886 - val_accuracy: 0.8459 - val_loss: 0.5414\n",
            "Epoch 108/125\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8906 - loss: 0.3192 - val_accuracy: 0.8503 - val_loss: 0.5313\n",
            "Epoch 109/125\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.47702\n",
            "781/781 - 41s - 52ms/step - accuracy: 0.8567 - loss: 0.4882 - val_accuracy: 0.8528 - val_loss: 0.5292\n",
            "Epoch 110/125\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8281 - loss: 0.5620 - val_accuracy: 0.8541 - val_loss: 0.5231\n",
            "Epoch 111/125\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.47702\n",
            "781/781 - 39s - 49ms/step - accuracy: 0.8561 - loss: 0.4865 - val_accuracy: 0.8614 - val_loss: 0.4910\n",
            "Epoch 112/125\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8906 - loss: 0.3651 - val_accuracy: 0.8626 - val_loss: 0.4890\n",
            "Epoch 113/125\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.47702\n",
            "781/781 - 40s - 52ms/step - accuracy: 0.8595 - loss: 0.4775 - val_accuracy: 0.8592 - val_loss: 0.5160\n",
            "Epoch 114/125\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8438 - loss: 0.6254 - val_accuracy: 0.8586 - val_loss: 0.5115\n",
            "Epoch 115/125\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.47702\n",
            "781/781 - 39s - 50ms/step - accuracy: 0.8589 - loss: 0.4832 - val_accuracy: 0.8625 - val_loss: 0.4953\n",
            "Epoch 116/125\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.8438 - loss: 0.5724 - val_accuracy: 0.8609 - val_loss: 0.4957\n",
            "Epoch 117/125\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.47702\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.8617 - loss: 0.4732 - val_accuracy: 0.8596 - val_loss: 0.5055\n",
            "Epoch 118/125\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.9219 - loss: 0.3244 - val_accuracy: 0.8585 - val_loss: 0.5075\n",
            "Epoch 119/125\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.47702\n",
            "781/781 - 29s - 37ms/step - accuracy: 0.8616 - loss: 0.4733 - val_accuracy: 0.8583 - val_loss: 0.5123\n",
            "Epoch 120/125\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8594 - loss: 0.4598 - val_accuracy: 0.8598 - val_loss: 0.5024\n",
            "Epoch 121/125\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.47702\n",
            "781/781 - 38s - 49ms/step - accuracy: 0.8617 - loss: 0.4739 - val_accuracy: 0.8491 - val_loss: 0.5398\n",
            "Epoch 122/125\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 2ms/step - accuracy: 0.8438 - loss: 0.4876 - val_accuracy: 0.8527 - val_loss: 0.5291\n",
            "Epoch 123/125\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.47702\n",
            "781/781 - 40s - 52ms/step - accuracy: 0.8624 - loss: 0.4746 - val_accuracy: 0.8586 - val_loss: 0.5221\n",
            "Epoch 124/125\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.47702\n",
            "781/781 - 1s - 1ms/step - accuracy: 0.9375 - loss: 0.3350 - val_accuracy: 0.8601 - val_loss: 0.5115\n",
            "Epoch 125/125\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.47702\n",
            "781/781 - 28s - 36ms/step - accuracy: 0.8625 - loss: 0.4704 - val_accuracy: 0.8645 - val_loss: 0.4909\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "batch_size = 64\n",
        "epochs=125\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import RMSprop # Import the RMSprop class\n",
        "\n",
        "# Change the filepath extension from .hdf5 to .keras\n",
        "checkpointer = ModelCheckpoint(filepath='model.125epochs.keras', verbose=1, save_best_only=True)\n",
        "\n",
        "# you can try any of these optimizers by uncommenting the line\n",
        "# optimizer = keras.optimizers.Adam(learning_learning_rate=0.0005,decay=1e-6) # Use the class name Adam\n",
        "\n",
        "# Instantiate the RMSprop optimizer class\n",
        "optimizer = RMSprop(learning_rate=0.0003, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "# Use the fit method instead of fit_generator\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), callbacks=[checkpointer],\n",
        "                steps_per_epoch=x_train.shape[0] // batch_size, epochs=epochs,verbose=2,\n",
        "                validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEkRBUWMMZYO",
        "outputId": "1f8f3f25-adf5-4506-cdc1-50ace56444b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 9728/10000 [============================>.] - ETA: 0s\n",
            "Test result: 89.590 loss: 0.403\n"
          ]
        }
      ],
      "source": [
        "# evaluating the model\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Jrg_0JHlMZYP",
        "outputId": "9f6748fa-4801-414d-911e-6e9fa2d26b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot learning curves of model accuracy\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:deep_learning] *",
      "language": "python",
      "name": "conda-env-deep_learning-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}