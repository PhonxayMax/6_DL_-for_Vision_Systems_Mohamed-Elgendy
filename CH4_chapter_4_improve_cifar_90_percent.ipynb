{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhonxayMax/6_DL_-for_Vision_Systems_Mohamed-Elgendy/blob/main/CH4_chapter_4_improve_cifar_90_percent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "v5ScYs9jMZYL"
      },
      "outputs": [],
      "source": [
        "# Checked 25/05/2025\n",
        "#import dependencies\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "#from keras.utils import np_utils\n",
        "# Import to_categorical directly from keras.utils\n",
        "from keras.utils import to_categorical\n",
        "# Update the import statement for ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wx56a5EHMZYM",
        "outputId": "069d2c73-0c96-4c29-faf7-e2e9830d5f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "training data =  (50000, 32, 32, 3)\n",
            "testing data =  (10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# download and split the data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "print(\"training data = \", x_train.shape)\n",
        "print(\"testing data = \", x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": true,
        "id": "xU-aEyD7MZYM",
        "outputId": "f9b00d7d-dc88-4179-8b84-8f8418549b27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.9619245 , -0.91515917, -0.8995707 ],\n",
              "        [-1.2113398 , -1.1645745 , -1.1801629 ],\n",
              "        [-1.1022207 , -1.1333976 , -1.2113398 ],\n",
              "        ...,\n",
              "        [ 0.58133286,  0.17603296, -0.19809005],\n",
              "        [ 0.48780212,  0.06691375, -0.2916208 ],\n",
              "        [ 0.4254483 ,  0.05132529, -0.27603233]],\n",
              "\n",
              "       [[-1.6322283 , -1.5698744 , -1.5698744 ],\n",
              "        [-1.8816435 , -1.8816435 , -1.8816435 ],\n",
              "        [-1.6010513 , -1.756936  , -1.8816435 ],\n",
              "        ...,\n",
              "        [ 0.03573683, -0.5098592 , -1.0242784 ],\n",
              "        [-0.026617  , -0.5878015 , -1.1022207 ],\n",
              "        [ 0.02014837, -0.52544767, -0.9931014 ]],\n",
              "\n",
              "       [[-1.4919322 , -1.5075206 , -1.554286  ],\n",
              "        [-1.6322283 , -1.7725244 , -1.8816435 ],\n",
              "        [-1.117809  , -1.4607552 , -1.756936  ],\n",
              "        ...,\n",
              "        [-0.04220546, -0.57221305, -1.1022207 ],\n",
              "        [-0.01102854, -0.57221305, -1.1022207 ],\n",
              "        [-0.18250158, -0.7436861 , -1.2269284 ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 1.3607558 ,  0.7683944 , -0.38515157],\n",
              "        [ 1.2516366 ,  0.5033906 , -1.3516359 ],\n",
              "        [ 1.2048712 ,  0.62809825, -1.4763436 ],\n",
              "        ...,\n",
              "        [ 0.6125098 ,  0.19162142, -0.79045147],\n",
              "        [-1.0086899 , -1.3984014 , -1.7725244 ],\n",
              "        [-1.0554553 , -1.3516359 , -1.5698744 ]],\n",
              "\n",
              "       [[ 0.924279  ,  0.28515217, -0.38515157],\n",
              "        [ 0.81515974,  0.03573683, -1.2269284 ],\n",
              "        [ 1.0178097 ,  0.36309445, -1.4139898 ],\n",
              "        ...,\n",
              "        [ 0.9866328 ,  0.4254483 , -0.41632846],\n",
              "        [-0.3695631 , -0.91515917, -1.3516359 ],\n",
              "        [-0.5878015 , -1.0554553 , -1.3516359 ]],\n",
              "\n",
              "       [[ 0.8775136 ,  0.36309445, -0.07338238],\n",
              "        [ 0.7372175 ,  0.12926759, -0.41632846],\n",
              "        [ 0.9086905 ,  0.33191755, -0.52544767],\n",
              "        ...,\n",
              "        [ 1.4854635 ,  0.9866328 ,  0.30074063],\n",
              "        [ 0.4722137 , -0.04220546, -0.57221305],\n",
              "        [ 0.03573683, -0.44750538, -0.75927454]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Normalize the data to speed up training\n",
        "mean = np.mean(x_train)\n",
        "std = np.std(x_train)\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        "\n",
        "# let's look at the normalized values of a sample image\n",
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BUdWT70BMZYN",
        "outputId": "b9e43d12-adbc-4615-fb0c-009e9291f0e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# one-hot encode the labels in train and test datasets\n",
        "# we use “to_categorical” function in keras\n",
        "\n",
        "num_classes = 10\n",
        "# Use to_categorical directly after importing it\n",
        "y_train = to_categorical(y_train,num_classes)\n",
        "y_test = to_categorical(y_test,num_classes)\n",
        "\n",
        "# let's display one of the one-hot encoded labels\n",
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fTjVDFvUMZYN",
        "outputId": "d4b16ec6-b08c-4450-e45d-c6875c5adb24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m20,490\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,490</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m309,290\u001b[0m (1.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">309,290</span> (1.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m308,394\u001b[0m (1.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">308,394</span> (1.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# build the model\n",
        "\n",
        "# number of hidden units variable\n",
        "# we are declaring this variable here and use it in our CONV layers to make it easier to update from one place\n",
        "base_hidden_units = 32\n",
        "\n",
        "# l2 regularization hyperparameter\n",
        "weight_decay = 1e-4\n",
        "\n",
        "# instantiate an empty sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# CONV1\n",
        "# notice that we defined the input_shape here because this is the first CONV layer.\n",
        "# we don’t need to do that for the remaining layers\n",
        "model.add(Conv2D(base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV2\n",
        "model.add(Conv2D(base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# CONV3\n",
        "model.add(Conv2D(2*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV4\n",
        "model.add(Conv2D(2*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# CONV5\n",
        "model.add(Conv2D(4*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV6\n",
        "model.add(Conv2D(4*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# FC7\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# print model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4yAcChREMZYO"
      },
      "outputs": [],
      "source": [
        "# data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        "    )\n",
        "\n",
        "# compute the data augmentation on the training set\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": false,
        "id": "CPvt9kbwMZYO",
        "outputId": "5e285e53-913d-46cd-8840-8e70b629be4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5a78526961c6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Use the fit method instead of fit_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), callbacks=[checkpointer],\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 validation_data=(x_test,y_test))\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# training\n",
        "batch_size = 64\n",
        "epochs=125\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import RMSprop # Import the RMSprop class\n",
        "\n",
        "# Change the filepath extension from .hdf5 to .keras\n",
        "checkpointer = ModelCheckpoint(filepath='model.125epochs.keras', verbose=1, save_best_only=True)\n",
        "\n",
        "# you can try any of these optimizers by uncommenting the line\n",
        "# optimizer = keras.optimizers.Adam(learning_learning_rate=0.0005,decay=1e-6) # Use the class name Adam\n",
        "\n",
        "# Instantiate the RMSprop optimizer class\n",
        "optimizer = RMSprop(learning_rate=0.0003, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "# Use the fit method instead of fit_generator\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), callbacks=[checkpointer],\n",
        "                steps_per_epoch=x_train.shape[0] // batch_size, epochs=epochs,verbose=2,\n",
        "                validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEkRBUWMMZYO",
        "outputId": "1f8f3f25-adf5-4506-cdc1-50ace56444b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 9728/10000 [============================>.] - ETA: 0s\n",
            "Test result: 89.590 loss: 0.403\n"
          ]
        }
      ],
      "source": [
        "# evaluating the model\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jrg_0JHlMZYP",
        "outputId": "043faaaf-3be5-41dd-e46b-e4c67df1296f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYUjDXSmlwpCGu1JKhSENd6WUCkP/HwMfMCaFjbXoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fcf31e489d0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot learning curves of model accuracy\n",
        "pyplot.plot(history.history['acc'], label='train')\n",
        "pyplot.plot(history.history['val_acc'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:deep_learning] *",
      "language": "python",
      "name": "conda-env-deep_learning-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}